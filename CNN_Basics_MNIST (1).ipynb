{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Basics_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oVEReyyDtZxl"
      },
      "source": [
        "# CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyOlxWnTALE8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K0cQhGAxl_qs",
        "outputId": "44c337d8-b90b-49c8-d8c3-0cd9653a1357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.rcParams['figure.figsize'] = (15, 8)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKTF0G1tpqHX",
        "colab_type": "code",
        "outputId": "67a267c6-4a5a-40ba-e03a-aadaad1c5e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4MO0jk-XuVIJ"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fpGB4hjTof55",
        "outputId": "23cee9a2-bf0e-4e6a-da9c-b4efb39c4769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%matplotlib inline\n",
        "# Load/Prep the Data\n",
        "(x_train, y_train_num), (x_test, y_test_num) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = np_utils.to_categorical(y_train_num, 10)\n",
        "y_test = np_utils.to_categorical(y_test_num, 10)\n",
        "\n",
        "print('--- THE DATA ---')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- THE DATA ---\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MPoPtByINyrA",
        "outputId": "a2918e90-7905-4a47-9985-d29c7a56dbe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "erfoPAKnu1bw"
      },
      "source": [
        "##DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f1su9BsaMpGI",
        "colab": {}
      },
      "source": [
        "TRAIN = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PXfm1xpmp9Kd",
        "outputId": "12d85f64-9e7e-4a10-9ebf-2d57a5e0d9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        }
      },
      "source": [
        "    # Define the Type of Model\n",
        "    model1 = Sequential()\n",
        "\n",
        "    # Flatten Imgaes to Vector\n",
        "    model1.add(Reshape((784,), input_shape=(28, 28, 1)))\n",
        "\n",
        "    # Layer 1\n",
        "    model1.add(Dense(output_dim=128, init='he_normal', bias=True))\n",
        "    model1.add(Activation(\"relu\"))\n",
        "\n",
        "    # Layer 2\n",
        "    model1.add(Dense(output_dim=10, init='he_normal', bias=True))\n",
        "    model1.add(Activation(\"softmax\"))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]# [stats, early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model1.fit(x_train, y_train, nb_epoch=EPOCHS, batch_size=BATCH_SIZE,\n",
        "              validation_data=(x_test, y_test), callbacks=callback_list, verbose=True)\n",
        "    \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=128, kernel_initializer=\"he_normal\", use_bias=True)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"he_normal\", use_bias=True)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 17s 282us/step - loss: 0.2574 - acc: 0.9276 - val_loss: 0.1308 - val_acc: 0.9606\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1129 - acc: 0.9663 - val_loss: 0.1012 - val_acc: 0.9689\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0764 - acc: 0.9768 - val_loss: 0.0911 - val_acc: 0.9719\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0572 - acc: 0.9818 - val_loss: 0.0760 - val_acc: 0.9773\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0435 - acc: 0.9862 - val_loss: 0.0824 - val_acc: 0.9759\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0353 - acc: 0.9892 - val_loss: 0.0686 - val_acc: 0.9791\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0735 - val_acc: 0.9781\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0810 - val_acc: 0.9752\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0184 - acc: 0.9945 - val_loss: 0.0771 - val_acc: 0.9779\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0151 - acc: 0.9957 - val_loss: 0.0902 - val_acc: 0.9778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb475d7dcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cRbEC7UktxyX",
        "outputId": "f5d7c60e-1a5a-4d12-8bf2-bc12918af154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss_and_metrics = model1.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 39us/step\n",
            "[0.09017811603728042, 0.9778]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ojlt4qYvCmx"
      },
      "source": [
        "## Vanilla CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "py3GWN2kUfys",
        "colab": {}
      },
      "source": [
        "TRAIN = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVAkTinRLBDp",
        "outputId": "66b2e123-58aa-4a28-d121-f2ea67aabcdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "\n",
        "    # Define model\n",
        "    model2 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(128))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model2.add(Dense(10))\n",
        "    model2.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model2\n",
        "    model2.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 17s 284us/step - loss: 0.1132 - acc: 0.9655 - val_loss: 0.0612 - val_acc: 0.9799\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0380 - acc: 0.9881 - val_loss: 0.0406 - val_acc: 0.9867\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0223 - acc: 0.9928 - val_loss: 0.0396 - val_acc: 0.9866\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0463 - val_acc: 0.9871\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0532 - val_acc: 0.9864\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0460 - val_acc: 0.9888\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.0517 - val_acc: 0.9885\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0530 - val_acc: 0.9889\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0559 - val_acc: 0.9886\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0615 - val_acc: 0.9863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb468318160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnwqJ15yULf8",
        "outputId": "10a06f15-4a94-452d-bbc2-d8a7378561b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss_and_metrics = model2.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 67us/step\n",
            "[0.06149636349061297, 0.9863]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-dqbAnSdvITA"
      },
      "source": [
        "## Vanilla CNN + Pooling + Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jmWB_HYiXQpk",
        "colab": {}
      },
      "source": [
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tMnK0A84VqZc",
        "outputId": "45d05aa6-d5b2-4726-8a8b-c368b06bac6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "\n",
        "    # Define Model\n",
        "    model3 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # Max Pooling\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    # Dropout\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model3.add(Flatten())\n",
        "    model3.add(Dense(128))\n",
        "    model3.add(Activation('relu'))\n",
        "    \n",
        "    # More Dropout\n",
        "    model3.add(Dropout(0.5))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model3.add(Dense(10))\n",
        "    model3.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=7, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model3.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
        "    \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.1924 - acc: 0.9403 - val_loss: 0.0477 - val_acc: 0.9852\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0848 - acc: 0.9749 - val_loss: 0.0472 - val_acc: 0.9843\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0656 - acc: 0.9802 - val_loss: 0.0327 - val_acc: 0.9894\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0541 - acc: 0.9836 - val_loss: 0.0317 - val_acc: 0.9900\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0490 - acc: 0.9851 - val_loss: 0.0282 - val_acc: 0.9903\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0407 - acc: 0.9870 - val_loss: 0.0322 - val_acc: 0.9899\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0382 - acc: 0.9881 - val_loss: 0.0276 - val_acc: 0.9914\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0344 - acc: 0.9890 - val_loss: 0.0294 - val_acc: 0.9914\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0310 - acc: 0.9899 - val_loss: 0.0281 - val_acc: 0.9914\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0279 - acc: 0.9909 - val_loss: 0.0255 - val_acc: 0.9924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4680fde80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xCP8O8OuXurL",
        "outputId": "2127f871-e750-4f87-aea8-368b4fe8054f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss_and_metrics = model3.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 57us/step\n",
            "[0.025451706372490755, 0.9924]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouJUX_i1mY6o",
        "colab_type": "code",
        "outputId": "f85b2310-656e-4d14-e200-62c3fcf4340b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss_and_metrics = model3.evaluate(x_train, y_train)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 61us/step\n",
            "[0.00512308710640591, 0.99855]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}