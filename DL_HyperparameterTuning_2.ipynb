{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DL_HyperparameterTuning_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreatLearningAIML1/bangalore-aug19-batch-suneethasomesula/blob/master/DL_HyperparameterTuning_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugSqxyVrmgmo",
        "colab_type": "text"
      },
      "source": [
        "# Activation function evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pgdLIMumgmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "51b9a3ab-0599-4892-e016-79c9a23e47a0"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import BatchNormalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbwWHGVHmgm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "29c61c64-8d1b-4c14-da38-97cfb0d86ebb"
      },
      "source": [
        "# https://corochann.com/mnist-dataset-introduction-1138.html  Introdcution to MNIST dataset\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "num_classes = 10\n",
        "x_train = x_train.reshape(60000, 784)    # 784 = 28 X 28 the size of each image. There are 60000 images for training\n",
        "x_test = x_test.reshape(10000, 784)      # Images are flattended out into a vector of 784 elements\n",
        "x_train = x_train.astype('float32')      # Change the data type to float from integer (0 - 255)\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255                           # Scale the data between 0 and 1\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)   # Converting the target into categorical which is stored as numeric\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)     # Keras converst these into 1-hot coded vectors as these are lables\n",
        "\n",
        "\n",
        "print ('Train size:', x_train.shape[0])\n",
        "print ('Test size:', x_test.shape[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "Train size: 60000\n",
            "Test size: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKubyepNmgm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "dec7b549-e8b2-450e-b4de-ebfade45e270"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(784, activation='relu', input_shape=(784,)))   #First hidden layer of 784  neurons, each neuron takes input \n",
        "                                                               # vector of size 784\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
        "                                                               # neurons as the number of classes (10) which is also the \n",
        "                                                               # the shape of each output vector ( one hot coded)\n",
        "\n",
        "                                                               # output layer also uses softmax. This normalizes the values \n",
        "                                                               # from the ten output nodes such that: \n",
        "                                                               #        all the values are between 0 and 1, and\n",
        "                                                               #        the sum of all ten values is 1.  \n",
        "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
        "        \n",
        "        \n",
        "\n",
        "for l in model.layers:\n",
        "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
        "print()\n",
        "print (model.summary())\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "dense_1 (None, 784) ==> (None, 784)\n",
            "dense_2 (None, 784) ==> (None, 10)\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQ_jgudmgm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "12fc5f25-c5e1-40f1-fec9-93aae5bb6b8b"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 20\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
        "loss,acc  = model.evaluate(x_test, y_test, verbose=False)\n",
        "print(\"model accuracy :\" , accuracy)\n",
        "#print(\"validation accuracy : \", val_acc)\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('acc / loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model accuracy : 0.9782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlnEOAjOzjHMQmJll3P8HN6GgnF8ymK4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtG5ToKDmgnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "3ae22104-2a52-4fa0-dd12-32cf9ebcfafe"
      },
      "source": [
        "print(history.history['val_acc'])\n",
        "\n",
        "print(history.history['acc'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['acc'])\n",
        "va = pd.DataFrame(history.history['val_acc'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9826666661898296, 0.9836666668256124, 0.9844999995231628, 0.9848333328564962, 0.9866666661898295, 0.9863333328564962, 0.9858333328564962, 0.9866666661898295, 0.9863333328564962, 0.9863333328564962, 0.9869999995231629, 0.9866666661898295, 0.9866666661898295, 0.9861666661898295, 0.9864999995231628, 0.9863333328564962, 0.9866666661898295, 0.9871666661898295, 0.9864999995231628, 0.9868333328564962]\n",
            "[0.9984074074250681, 0.9996296296296296, 0.9989444444444444, 0.9998888888888889, 0.9999444444444444, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e7d500d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncv4/w2LHAjqCwQsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zkalfpomgnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With simple two layer NN, got an accuracy of 98%+ \n",
        "# But training and validation scores are in different ranges ... looks like overfitting case\n",
        "# The accuracy is reached quite early in the epochs within first 5\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUmglC4BmgnM",
        "colab_type": "text"
      },
      "source": [
        "# Number of hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rltVUWdEmgnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dense(layer_sizes):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(layer_sizes[0], activation='relu', input_shape=(784,)))\n",
        "\n",
        "    for s in layer_sizes[1:]:\n",
        "        model.add(Dense(units = s, activation = 'relu'))\n",
        "\n",
        "    model.add(Dense(units=num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "def evaluate(model, batch_size=batch_size, epochs=epochs):\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
        "    loss,accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "    \n",
        "    print(\"Model accuracy : \", acc)\n",
        " \n",
        "    \n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('acc / loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNz83AwumgnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "371e2717-20c3-4329-89dc-ce567ae69c93"
      },
      "source": [
        "for layers in range(2,4):\n",
        "    model = create_dense([784] * layers)\n",
        "    evaluate(model)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 1,238,730\n",
            "Trainable params: 1,238,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model accuracy :  0.9844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4v4/dmO67Axx1/oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 1,854,170\n",
            "Trainable params: 1,854,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model accuracy :  0.9844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhARiTglAhGRiPv/vQA1mKJ8eXAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1ong6QQmgnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "4e5b609a-fbcb-4f8c-c79c-4f6bba570e69"
      },
      "source": [
        "print(history.history['val_acc'])\n",
        "\n",
        "print(history.history['acc'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['acc'])\n",
        "va = pd.DataFrame(history.history['val_acc'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9826666661898296, 0.9836666668256124, 0.9844999995231628, 0.9848333328564962, 0.9866666661898295, 0.9863333328564962, 0.9858333328564962, 0.9866666661898295, 0.9863333328564962, 0.9863333328564962, 0.9869999995231629, 0.9866666661898295, 0.9866666661898295, 0.9861666661898295, 0.9864999995231628, 0.9863333328564962, 0.9866666661898295, 0.9871666661898295, 0.9864999995231628, 0.9868333328564962]\n",
            "[0.9984074074250681, 0.9996296296296296, 0.9989444444444444, 0.9998888888888889, 0.9999444444444444, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e7d0b34a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAaZklEQVR4nO3df5BV5Z3n8fdnu0Gj0TgrmR4XDFAl\nW9Mtw6C2Gg0ZGykzoBNR4k7oMkYnHUlm1biTYInVVVqy00ESLUcHN1OsjaNb2TYpJmVwxagLfQso\ndRbMCgK9OoxZFXQSf0SdJlHp3u/+cZ9uD/c09Om26dtpP6+qW5zznOc55zm3jv3xPM+59yoiMDMz\ny/o31e6AmZmNPQ4HMzPLcTiYmVmOw8HMzHIcDmZmllNb7Q6MhEmTJsW0adOq3Y1xY//+/Rx77LHV\n7oZZjq/NkfXMM8+8ERGfHmjbuAiHadOmsW3btmp3Y9wolUo0NTVVuxtmOb42R5aklw61zcNKZmaW\n43AwM7Mch4OZmeU4HMzMLMfhYGZmOYXCQdIaSb+StPMQ2yXpbkl7JO2QdHpm25WS/im9rsyUnyHp\nudTmbklK5f9W0hOp/hOSfu+jnqSZmQ1N0TuHvwfmH2b7AmBGei0BfgDlP/TALcDZwFnALZk/9j8A\nrs6069v/MmBDRMwANqR1GwUdHR3MnDmTefPmMXPmTDo6OqrdJTOrkkLhEBGbgLcOU2Uh8ECUPQ2c\nIOkk4E+BJyLirYj4NfAEMD9tOz4ino7yd4Y/AFyS2df9afn+TLkdQR0dHVx//fXs37+fiGD//v1c\nf/31Dgizj6mR+hDcZOCVzPreVHa48r0DlAPURcRraflfgLqBDihpCeW7FOrq6iiVSh/tDMap6166\nrnDduu+X3+pTORWAT/JJvvvBd/nu/d8dtO3fTv3b4XXQbAi6u7v93/ooGdOfkI6IkDTgrxFFxGpg\nNUBjY2P4U5MDe47nCtWTxLJly3j44Yfp6uqivr6eL37xi9x22234B6FsrPAnpEfPSIXDPuDkzPqU\nVLYPaKooL6XyKQPUB/ilpJMi4rU0/PSrEeqjDeK+++6jo6OD3t5eampqaG5urnaXzKxKRupR1nXA\nV9NTS58F3klDQ48BX5D0e2ki+gvAY2nbu5I+m55S+irw08y++p5qujJTbkdQbW0tBw4cOKjswIED\n1NaO6ZtLMztCCv2XL6mD8h3AJEl7KT+BNAEgIv4OWA9cCOwBfgP8Rdr2lqT/DGxNu1oeEX0T2/+R\n8lNQnwAeTS+A24AfS2oBXgL+fPinZ0X13S187Wtf4+WXX+Yzn/kMNTU19Pb2VrtrZlYFhcIhIg47\nvpCeOLrmENvWAGsGKN8GzByg/E1gXpF+2chpaGjgkksu4aGHHgLg2GOP5fLLL+9fN7OPF48ZGACt\nra20trbS3t7efxfR0tJCW1tbtbtmZlXgcDCA/snn6667rv9ppba2Nk9Km31MORysX3NzM83NzX5c\n0Mz8xXv2IX99hpn18Z2DAeVgGGjOAfDQktnHkO8cDIC2tjba29uZO3cutbW1zJ07l/b2dk9Im31M\nORwMgK6uLubMmXNQ2Zw5c+jq6qpSj8ysmhwOBkB9fT1btmw5qGzLli3U19dXqUdmVk0OBwPKn3No\naWmhs7OTnp4eOjs7aWlpobW1tdpdM7Mq8IS0AeVJ5yeffJIFCxbw/vvvc9RRR3H11Vd7MtrsY8rh\nYED5aaVHHnmERx999KCnlc4991wHhNnHkIeVDPDTSmZ2MIeDAX5aycwO5nAwwE8rmdnBHA4G+Gkl\nMzuYJ6QN8LeymtnBHA7Wz9/KamZ9PKxkZmY5DgczM8txOJiZWU6hcJA0X9LzkvZIWjbA9qmSNkja\nIakkaUpm20pJO9Pry5nyzZKeTa9XJT2UypskvZPZdvNInKiZmRU36IS0pBrgHuACYC+wVdK6iNid\nqXY78EBE3C/pfGAFcIWki4DTgdnAUUBJ0qMR8W5EfD5zjH8AfprZ3+aI+LOPenJmZjY8Re4czgL2\nRMSLEfEB8CCwsKJOA7AxLXdmtjcAmyKiJyL2AzuA+dmGko4HzgceGt4pmJnZSCvyKOtk4JXM+l7g\n7Io624FFwF3ApcBxkk5M5bdIugM4BpgL7K5oewmwISLezZSdI2k78CqwNCJ2VXZK0hJgCUBdXR2l\nUqnAqVgR3d3dfj9tTPK1OXpG6nMOS4FVkq4CNgH7gN6IeFzSmcCTwOvAU0BvRdtm4N7M+s+BqRHR\nLelCyncUMyoPGBGrgdUAjY2N4efyR44/52Bjla/N0VNkWGkfcHJmfUoq6xcRr0bEoog4DWhNZW+n\nf9siYnZEXAAIeKGvnaRJlIetHsns692I6E7L64EJqZ6ZmY2SIuGwFZghabqkicBiYF22gqRJkvr2\ndROwJpXXpOElJM0CZgGPZ5peBvyPiHgvs68/kKS0fFbq45vDOTkzMxueQYeVIqJH0rXAY0ANsCYi\ndklaDmyLiHVAE7BCUlAeVromNZ8AbE5/698FvhIRPZndLwZuqzjkZcBfSuoBfgssjogY7gmamdnQ\nFZpzSMM76yvKbs4srwXWDtDuPcpPLB1qv00DlK0CVhXpl5mZHRn+hLSZmeU4HMzMLMfhYGZmOQ4H\nMzPLcTiYmVmOw8HMzHIcDmZmluNwMDOzHIeDmZnlOBzMzCzH4WBmZjkOBzMzy3E4mJlZjsPBzMxy\nHA5mZpbjcDAzsxyHg5mZ5TgczMwsx+FgZmY5hcJB0nxJz0vaI2nZANunStogaYekkqQpmW0rJe1M\nry9nyv9e0i8kPZtes1O5JN2djrVD0ukjcaJmZlbcoOEgqQa4B1gANADNkhoqqt0OPBARs4DlwIrU\n9iLgdGA2cDawVNLxmXY3RMTs9Ho2lS0AZqTXEuAHwz05MzMbniJ3DmcBeyLixYj4AHgQWFhRpwHY\nmJY7M9sbgE0R0RMR+4EdwPxBjreQctBERDwNnCDppAL9NDOzEVJboM5k4JXM+l7KdwFZ24FFwF3A\npcBxkk5M5bdIugM4BpgL7M60a5N0M7ABWBYR7x/ieJOB17IHlLSE8p0FdXV1lEqlAqdiRXR3d/v9\ntDHJ1+boKRIORSwFVkm6CtgE7AN6I+JxSWcCTwKvA08BvanNTcC/ABOB1cCNlIekComI1akdjY2N\n0dTUNCInYlAqlfD7aWORr83RU2RYaR9wcmZ9SirrFxGvRsSiiDgNaE1lb6d/29KcwgWAgBdS+Wtp\n6Oh94D7Kw1eFjmdmZkdWkXDYCsyQNF3SRGAxsC5bQdIkSX37uglYk8pr0vASkmYBs4DH0/pJ6V8B\nlwA7U/t1wFfTU0ufBd6JiIOGlMzM7MgadFgpInokXQs8BtQAayJil6TlwLaIWAc0ASskBeVhpWtS\n8wnA5vLff94FvhIRPWnbDyV9mvLdxLPAN1P5euBCYA/wG+AvPvJZmpnZkBSac4iI9ZT/aGfLbs4s\nrwXWDtDuPcpPLA20z/MPUR58GC5mZlYF/oS0mZnlOBzMzCzH4WBmZjkOBzMzy3E4mJlZjsPBzMxy\nHA5mZpbjcDAzsxyHg5mZ5TgczMwsx+FgZmY5DgczM8txOJiZWY7DwczMchwOZmaW43AwM7Mch4OZ\nmeU4HMzMLMfhYGZmOQ4HMzPLKRQOkuZLel7SHknLBtg+VdIGSTsklSRNyWxbKWlnen05U/7DtM+d\nktZImpDKmyS9I+nZ9Lp5JE7UzMyKGzQcJNUA9wALgAagWVJDRbXbgQciYhawHFiR2l4EnA7MBs4G\nlko6PrX5IfCHwB8BnwC+ntnf5oiYnV7Lh3tyZmY2PEXuHM4C9kTEixHxAfAgsLCiTgOwMS13ZrY3\nAJsioici9gM7gPkAEbE+EuB/AVMwM7MxobZAncnAK5n1vZTvArK2A4uAu4BLgeMknZjKb5F0B3AM\nMBfYnW2YhpOuAK7PFJ8jaTvwKrA0InZVdkrSEmAJQF1dHaVSqcCpWBHd3d1+P21M8rU5eoqEQxFL\ngVWSrgI2AfuA3oh4XNKZwJPA68BTQG9F2/9C+e5ic1r/OTA1IrolXQg8BMyoPGBErAZWAzQ2NkZT\nU9MInYqVSiX8ftpY5Gtz9BQZVtoHnJxZn5LK+kXEqxGxKCJOA1pT2dvp37Y0d3ABIOCFvnaSbgE+\nDXw7s693I6I7La8HJkiaNJyTMzOz4SkSDluBGZKmS5oILAbWZStImiSpb183AWtSeU0aXkLSLGAW\n8Hha/zrwp0BzRPy/zL7+QJLS8lmpj28O/xTNzGyoBh1WiogeSdcCjwE1wJqI2CVpObAtItYBTcAK\nSUF5WOma1HwCsDn9rX8X+EpE9KRtfwe8BDyVtv8kPZl0GfCXknqA3wKL06S1mZmNkkJzDml4Z31F\n2c2Z5bXA2gHavUf5iaWB9jngsSNiFbCqSL/MzOzI8Cekzcwsx+FgZmY5DgczM8txOJiZWY7DwczM\nchwOZmaW43AwM7Mch4OZmeU4HMzMLMfhYGZmOQ4HMzPLcTiYmVmOw8HMzHIcDmZmluNwMDOzHIeD\nmZnlOBzMzCzH4WBmZjkOBzMzyykUDpLmS3pe0h5JywbYPlXSBkk7JJUkTclsWylpZ3p9OVM+XdI/\npn3+SNLEVH5UWt+Ttk/76KdpZmZDMWg4SKoB7gEWAA1As6SGimq3Aw9ExCxgObAitb0IOB2YDZwN\nLJV0fGqzErgzIk4Bfg20pPIW4Nep/M5Uz8zMRlGRO4ezgD0R8WJEfAA8CCysqNMAbEzLnZntDcCm\niOiJiP3ADmC+JAHnA2tTvfuBS9LywrRO2j4v1Tczs1FSW6DOZOCVzPpeyncBWduBRcBdwKXAcZJO\nTOW3SLoDOAaYC+wGTgTejoiezD4nVx4vInokvZPqv5E9oKQlwBKAuro6SqVSgVOxIrq7u/1+2pjk\na3P0FAmHIpYCqyRdBWwC9gG9EfG4pDOBJ4HXgaeA3pE4YESsBlYDNDY2RlNT00js1oBSqYTfTxuL\nfG2OniLDSvuAkzPrU1JZv4h4NSIWRcRpQGsqezv92xYRsyPiAkDAC8CbwAmSagfYZ//x0vZPpfpm\nZjZKioTDVmBGerpoIrAYWJetIGmSpL593QSsSeU1aXgJSbOAWcDjERGU5yYuS22uBH6altelddL2\njam+mZmNkkHDIc0LXAs8BnQBP46IXZKWS7o4VWsCnpf0AlAHtKXyCcBmSbspDwF9JTPPcCPwbUl7\nKM8ptKfyduDEVP5tIPforJmZHVmF5hwiYj2wvqLs5szyWj588ihb5z3KTywNtM8XKT8JNVCb/1Ck\nX2ZmdmT4E9JmZpbjcDAzsxyHg5mZ5TgczMwsx+FgZmY5DgczM8txOJiZWY7DwczMchwOZmaW43Aw\nM7Mch4OZmeU4HMzMLMfhYGZmOQ4HMzPLcTiYmVmOw8HMzHIcDmZmluNwMDOzHIeDmZnlOBzMzCyn\nUDhImi/peUl7JC0bYPtUSRsk7ZBUkjQls+17knZJ6pJ0t8qOk/Rs5vWGpL9J9a+S9Hpm29dH7nTN\nzKyI2sEqSKoB7gEuAPYCWyWti4jdmWq3Aw9ExP2SzgdWAFdIOhf4HDAr1dsCnBcRJWB25hjPAD/J\n7O9HEXHt8E/LzMw+iiJ3DmcBeyLixYj4AHgQWFhRpwHYmJY7M9sDOBqYCBwFTAB+mW0o6d8Dvw9s\nHs4JmJnZyBv0zgGYDLySWd8LnF1RZzuwCLgLuBQ4TtKJEfGUpE7gNUDAqojoqmi7mPKdQmTKviTp\nT4AXgL+KiFcq2iBpCbAEoK6ujlKpVOBUrIju7m6/nzYm+docPUXCoYilwCpJVwGbgH1Ar6RTgHqg\nbw7iCUmfj4jsXcJi4IrM+sNAR0S8L+kbwP3A+ZUHjIjVwGqAxsbGaGpqGqFTsVKphN9PG4t8bY6e\nIsNK+4CTM+tTUlm/iHg1IhZFxGlAayp7m/JdxNMR0R0R3cCjwDl97ST9MVAbEc9k9vVmRLyfVu8F\nzhj6aZmZ2UdRJBy2AjMkTZc0kfL/6a/LVpA0SVLfvm4C1qTll4HzJNVKmgCcB2SHlZqBjop9nZRZ\nvbiivpmZjYJBh5UiokfStcBjQA2wJiJ2SVoObIuIdUATsEJSUB5WuiY1X0t5SOg5ypPTP4uIhzO7\n/3PgwopDfkvSxUAP8BZw1TDPzcx+R0kaVruDpy7to9B4eDMbGxtj27Zt1e7GuOFxXRurpi17hP97\n20XV7sa4IemZiGgcaJs/IW1mZjkOBzMzy3E4mJlZzkh9zsHMbMj++NbHeee3B4bUZtqyR4ZU/1Of\nmMD2W74wpDbmcDCzKnrntweGNME8nIclhhomVuZhJTMzy/Gdg5lVzXH1y/ij+3O/AnB49w/1GAB+\n/HWoHA5mVjX/2nWbh5XGKA8rmZlZjsPBzMxyPKxkZlU15GGfnw39UVYbOoeDmVXNUL8nyd+tNHo8\nrGRmZjm+czCzMedwX9mtlYduNx6+ZXqs8J2DmY05ETHgq7Oz85DbHAwjy+FgZmY5DgczM8txOJiZ\nWY7DwczMcgqFg6T5kp6XtEdS7luyJE2VtEHSDkklSVMy274naZekLkl3Kz2GkOo9L+nZ9Pr9VH6U\npB+lY/2jpGkjc6pmZlbUoOEgqQa4B1gANADNkhoqqt0OPBARs4DlwIrU9lzgc8AsYCZwJnBept3l\nETE7vX6VylqAX0fEKcCdwGEeXDMzsyOhyJ3DWcCeiHgxIj4AHgQWVtRpADam5c7M9gCOBiYCRwET\ngF8OcryFfPilvGuBeTrcQ89mNu51dHQwc+ZM5s2bx8yZM+no6Kh2l8a9Ih+Cmwy8klnfC5xdUWc7\nsAi4C7gUOE7SiRHxlKRO4DVAwKqI6Mq0u09SL/APwF9H+UHl/uNFRI+kd4ATgTeyB5S0BFgCUFdX\nR6lUKnAqVkR3d7ffTxszNmzYQHt7OzfccAPTp0/nF7/4Bd/5znfYvXs38+bNq3b3xq/DfaAkfajk\nMuDezPoVlP/IZ+v8O+AnwP+mHBB7gROAU4BHgE+m11PA51Obyenf44DHga+m9Z3AlMy+/xmYdLg+\nnnHGGWEjp7Ozs9pdMOt36qmnxsaNGyPiw2tz48aNceqpp1axV+MDsC0O8Xe1yLDSPuDkzPqUVJYN\nmFcjYlFEnAa0prK3Kd9FPB0R3RHRDTwKnJO270v//ivw3ykPXx10PEm1wKeANwv008zGoa6uLubM\nmXNQ2Zw5c+jq6jpECxsJRcJhKzBD0nRJE4HFwLpsBUmTJPXt6yZgTVp+GThPUq2kCZQno7vS+qTU\ndgLwZ5TvGEj7vjItXwZsTAlnZh9D9fX13HrrrQfNOdx6663U19dXu2vj2qBzDlEe978WeAyoAdZE\nxC5JyynfkqwDmoAVkgLYBFyTmq8Fzgeeozw5/bOIeFjSscBjKRhqgP8J/NfUph34b5L2AG9RDiMz\n+5iaO3cuK1euZOXKlTQ0NLB7925uvPFGvvnNb1a7a+OaxsP/lDc2Nsa2bduq3Y1xYzi/02t2pMyc\nOZNLLrmEhx56iK6uLurr6/vXd+7cOfgO7JAkPRMRjQNuczhYJYeDjSU1NTW89957TJgwof/aPHDg\nAEcffTS9vb3V7t7vtMOFg78+w8zGtPr6erZs2XJQ2ZYtWzzncIQ5HMxsTGttbaWlpYXOzk56enro\n7OykpaWF1tbWandtXPMvwZnZmNbc3AzAdddd1z/n0NbW1l9uR4bDwczGvObmZpqbmz0fNoo8rGRm\nZjkOBzMzy3E4mNmY529lHX2eczCzMa2jo4PW1lba29vp7e2lpqaGlpYWAE9KH0G+czCzMa2trY32\n9nbmzp1LbW0tc+fOpb29nba2tmp3bVxzOJjZmOZvZa0Oh4OZjWn+hHR1OBzMbEzzJ6SrwxPSZjam\n+RPS1eFwMLMxz5+QHn0eVjIzsxyHg5mZ5TgczMwsx+FgZmOevz5j9HlC2szGNH99RnUUunOQNF/S\n85L2SFo2wPapkjZI2iGpJGlKZtv3JO2S1CXpbpUdI+kRSf8nbbstU/8qSa9Leja9vj4yp2pmv4v8\n9RnVMWg4SKoB7gEWAA1As6SGimq3Aw9ExCxgObAitT0X+BwwC5gJnAmc19cmIv4QOA34nKQFmf39\nKCJmp9e9wz47M/ud56/PqI4idw5nAXsi4sWI+AB4EFhYUacB2JiWOzPbAzgamAgcBUwAfhkRv4mI\nToC0z58DUzAzq+Cvz6iOInMOk4FXMut7gbMr6mwHFgF3AZcCx0k6MSKektQJvAYIWBURB8W9pBOA\nL6a2fb4k6U+AF4C/iojs8fvaLQGWANTV1VEqlQqcihXR3d3t99PGjEsvvZTLL7+cG264genTp3Pn\nnXfy/e9/n5aWFl+nR9BITUgvBVZJugrYBOwDeiWdAtTz4V3BE5I+HxGbASTVAh3A3RHxYqrzMNAR\nEe9L+gZwP3B+5QEjYjWwGqCxsTH8qcmR40+h2ljS1NREQ0MDbW1t/V+fcccdd3gy+ggrEg77gJMz\n61NSWb+IeJXynQOSPgl8KSLelnQ18HREdKdtjwLnAJtT09XAP0XE32T29WZm1/cC3xvSGZnZuOOv\nzxh9ReYctgIzJE2XNBFYDKzLVpA0SVLfvm4C1qTll4HzJNVKmkB5Mrortflr4FPAf6rY10mZ1Yv7\n6puZ2egZNBwioge4FniM8h/qH0fELknLJV2cqjUBz0t6AagD+p4xWwv8M/Ac5XmJ7RHxcHrUtZXy\nRPbPKx5Z/VZ6vHU78C3gqhE4TzMzG4JCcw4RsR5YX1F2c2Z5LeUgqGzXC3xjgPK9lCeoBzrWTZTv\nPszMrEr89RlmZpbjcDAzsxxFRLX78JFJeh14qdr9GEcmAW9UuxNmA/C1ObKmRsSnB9owLsLBRpak\nbRHRWO1+mFXytTl6PKxkZmY5DgczM8txONhAVle7A2aH4GtzlHjOwczMcnznYGZmOQ4HMzPLcThY\nv8F+Dtasmnx9ji7PORjQ/3OwLwAXUP5Bp61Ac0TsrmrHzPD1WQ2+c7A+RX4O1qxafH2OMoeD9Rno\n52AnV6kvZpV8fY4yh4OZmeU4HKzPoD8Ha1ZFvj5HmcPB+gz6c7BmVeTrc5QV+iU4G/8iokdS38/B\n1gBrImJXlbtlBvj6rAY/ympmZjkeVjIzsxyHg5mZ5TgczMwsx+FgZmY5DgczM8txOJiZWY7DwczM\ncv4/w2LHAjqCwQsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SEwpfx0mgnd",
        "colab_type": "text"
      },
      "source": [
        "## Observations about number of layers\n",
        "\n",
        "1. With one hidden layer of 784 neurons and one ouput layer of 10 the validation score is 98% rounded\n",
        "2. Increasing the hidden layer by one with same number of neurons shows the model is becoming wavy and overfit. Training accuracy is close to 1 while validation accuracy remains at 98% rounded\n",
        "3. Increasing the hidden layer by one more makes the situation even worse\n",
        "4. Returns are not enough to justify the number of parameters to learn\n",
        "5. Freeze number of hiddden layers to 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0M_Dqokmgng",
        "colab_type": "text"
      },
      "source": [
        "# Reduce number of neurons to 256 with only one hidden layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "godDn7LYmgnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b7fda130-41ff-4fca-cdc1-f39a0a96ab54"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(784,)))   \n",
        "model.add(Dense(num_classes, activation='softmax'))             \n",
        " \n",
        "for l in model.layers:\n",
        "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
        "print()\n",
        "print (model.summary())\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_10 (None, 784) ==> (None, 256)\n",
            "dense_11 (None, 256) ==> (None, 10)\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Oe-zNLmgnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "fd90637f-2c5a-4618-cc51-ed43ca892037"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 20\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
        "loss,accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "print(\"model accuracy :\" , accuracy)\n",
        "#print(\"validation accuracy : \", val_acc)\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('acc / loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model accuracy : 0.981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlnFOBGZmGedEYGaWcf8f3AS3zcC4w1cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAnVv7ZBmgnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "639db0ee-3255-435f-8cf9-cc78098514ac"
      },
      "source": [
        "print(history.history['val_acc'])\n",
        "\n",
        "print(history.history['acc'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['acc'])\n",
        "va = pd.DataFrame(history.history['val_acc'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9799999996821086, 0.9816666668256124, 0.9821666668256124, 0.9801666668256124, 0.9815000001589457, 0.9786666668256124, 0.9830000001589457, 0.9828333334922791, 0.982333333492279, 0.9836666668256124, 0.9840000001589457, 0.9840000001589457, 0.9838333334922791, 0.9838333334922791, 0.9835000001589457, 0.9830000001589457, 0.9836666668256124, 0.9831666668256124, 0.983333333492279, 0.9828333334922791]\n",
            "[0.9982222222398829, 0.9992962963139569, 0.9997592592592592, 0.9995555555555555, 0.9996481481481482, 0.9990185185361792, 0.9988703703703704, 0.9998518518518519, 0.9999629629629629, 0.9999814814814815, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e7d0b36a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqVAGgCQVygCQpEL9P0KmD93gQMaUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXvXP7cDmgnt",
        "colab_type": "text"
      },
      "source": [
        "## With 256 neurons and one hidden layer\n",
        "\n",
        "1. we are getting similar results in validation as with 784 neurons. \n",
        "2. The degree of overfit (between training and validation) is also reduced as is evident from training box plot\n",
        "\n",
        "3. With 128 neruons the validation accuracy drops to 97% rounded and the degree of overfit reduces further\n",
        "4. Futher reduction of neurons degrades the peformance both in training and validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4rMGaTBmgnu",
        "colab_type": "text"
      },
      "source": [
        "## Impact of batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjXZc-MMmgnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(784,)))   \n",
        "model.add(Dense(num_classes, activation='softmax'))              \n",
        "        \n",
        "        \n",
        "\n",
        "for l in model.layers:\n",
        "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
        "print()\n",
        "print (model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdZNXeEHmgn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256    \n",
        "epochs = 20\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1 )\n",
        "    \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#                    validation_data=(x_test, y_test), callbacks = [es])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=False)\n",
        "\n",
        "print()\n",
        "print ('Test loss:', round(score[0], 3))\n",
        "print ('Test accuracy:', round(score[1], 3))\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u-Ah93pmgn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CnOMHDwmgn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history['val_accuracy'])\n",
        "\n",
        "print(history.history['accuracy'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['accuracy'])\n",
        "va = pd.DataFrame(history.history['val_accuracy'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh2CcnV9mgoB",
        "colab_type": "text"
      },
      "source": [
        "## Observations on batch size\n",
        "\n",
        "1. With smaller batch size the model becomes unstable in validation (as is evident from the accuracy chart)\n",
        "2. Within the given 5 epochs the model becomes overfit (as is evident from the boxplot)\n",
        "3. The validation accuracy reduces "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBd1fz4cmgoC",
        "colab_type": "text"
      },
      "source": [
        "# Increase the Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQO7ULbCmgoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2ed70f1d-4047-4dee-a1ea-3b483cdf568c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(784,)))   \n",
        "model.add(Dense(num_classes, activation='softmax'))              \n",
        "        \n",
        "        \n",
        "\n",
        "for l in model.layers:\n",
        "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
        "print()\n",
        "print (model.summary())\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_12 (None, 784) ==> (None, 256)\n",
            "dense_13 (None, 256) ==> (None, 10)\n",
            "\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIi5olE7mgoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "b1252669-fdf4-432d-f200-fce9d97289e6"
      },
      "source": [
        "batch_size = 256    \n",
        "epochs = 50\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1 )\n",
        "    \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#                    validation_data=(x_test, y_test), callbacks = [es])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=False)\n",
        "\n",
        "print()\n",
        "print ('Test loss:', round(score[0], 3))\n",
        "print ('Test accuracy:', round(score[1], 3))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.3787 - acc: 0.8967 - val_loss: 0.1979 - val_acc: 0.9438\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1713 - acc: 0.9515 - val_loss: 0.1394 - val_acc: 0.9586\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1235 - acc: 0.9652 - val_loss: 0.1110 - val_acc: 0.9670\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0946 - acc: 0.9732 - val_loss: 0.0995 - val_acc: 0.9702\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0747 - acc: 0.9786 - val_loss: 0.0870 - val_acc: 0.9734\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0615 - acc: 0.9832 - val_loss: 0.0795 - val_acc: 0.9769\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0507 - acc: 0.9858 - val_loss: 0.0762 - val_acc: 0.9764\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0428 - acc: 0.9883 - val_loss: 0.0717 - val_acc: 0.9769\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0356 - acc: 0.9904 - val_loss: 0.0713 - val_acc: 0.9775\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0297 - acc: 0.9922 - val_loss: 0.0679 - val_acc: 0.9797\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0254 - acc: 0.9936 - val_loss: 0.0674 - val_acc: 0.9798\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0214 - acc: 0.9949 - val_loss: 0.0650 - val_acc: 0.9800\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0178 - acc: 0.9960 - val_loss: 0.0638 - val_acc: 0.9812\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0148 - acc: 0.9971 - val_loss: 0.0653 - val_acc: 0.9800\n",
            "Epoch 15/50\n",
            "31744/60000 [==============>...............] - ETA: 1s - loss: 0.0126 - acc: 0.9979"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnMUPt-dmgoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGZI31KKmgoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIuujEGnmgoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history['val_accuracy'])\n",
        "\n",
        "print(history.history['accuracy'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['accuracy'])\n",
        "va = pd.DataFrame(history.history['val_accuracy'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jsooJOXmgoZ",
        "colab_type": "text"
      },
      "source": [
        "## Observations on Epochs\n",
        "\n",
        "1. Without early stopping, epochs leads to clear overfitting\n",
        "2. Increasing Epochs is not useful. The Model becomes severly overfit\n",
        "3. With smaller batch size, looks like it is a case of curse of dimensionality.... \n",
        "4. large batch size of 30,000 the model stabilizes, avoids overfitting but the score is marginally reduced in validation. This shows that too many epochs with small batch size is a waste. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGxXYiEUmgoZ",
        "colab_type": "text"
      },
      "source": [
        "## Overall observation on layers, number of neurons, batch size and epoch\n",
        "1. Keep the model simple in terms of number of layers and number of neurons. This will reduce time to train, less computation\n",
        "   needs\n",
        "    \n",
        "2. Keep batch size on the larger side. It stabilizes the mode and gives more reliable estimates. If the entire data and fit in\n",
        "then do not use batch size \n",
        "\n",
        "3. Too many epochs is not helpful. It leads to waste of time and resources and overfit models Constrain epochs usining early \n",
        "stopping.\n",
        "\n",
        "4. use more epochs if the batch size is large. With smaller batch size, the model tends to overfit in first few epochs... the\n",
        "situation become worse with more epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-vXKMBEmgoa",
        "colab_type": "text"
      },
      "source": [
        "# Activation function selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMXAusiFmgob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 20\n",
        "\n",
        "for activation in [None, 'sigmoid', 'tanh', 'relu']:\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, activation=activation, input_shape=(784,)))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "    loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "    \n",
        "    print()\n",
        "    print(f'Test loss: {loss:.3}')\n",
        "    print(f'Test accuracy: {accuracy:.3}')\n",
        "    \n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['None', 'sigmoid', 'tanh', 'relu'], loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlMSBGvdmgof",
        "colab_type": "text"
      },
      "source": [
        "## Observations about choice of activation  functions\n",
        "\n",
        "1. The blue line is for a linear function and surprisingly it is giving 91% + accuracy!\n",
        "2. However, all the other standard activations ReLU, tanh, Sigmoid are performing relatively much better\n",
        "3. All converge to same 98% +- accuracy score with increase in epoch (upto 15)\n",
        "4. Any further increase in epochs may not help as all of them stop increasing beyond \n",
        "5. Sigmoid is the slowest learner followed by tanh while ReLU seems to learn fast...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoLkBanmmgoh",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate Optimization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-mQ5Mq9mgoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dense(num_classes, activation='softmax'))  \n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CchrHtAUmgol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def run_model(model, lr):\n",
        "    batch_size = 256    \n",
        "    epochs = 20\n",
        "    model.summary()\n",
        "    opt = keras.optimizers.Adam(learning_rate=lr) \n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
        "    loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "    print(\"learning rate\" , lr)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(f'Test loss: {loss:.3}')\n",
        "    print(f'Test accuracy: {accuracy:.3}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS_k18_Hmgop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "for lr in np.arange(0.010, 0.015 , 0.001):    # try lr of 0.005 to 0.10 in steps of 0.01\n",
        "    model = create_model()\n",
        "    run_model(model , lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "covILsV3mgos",
        "colab_type": "text"
      },
      "source": [
        "## Observations about choice of learning rate\n",
        "\n",
        "1. Too small learning rates such as 0.00001 requires large number of epochs to learn. Both training and testing scores are low\n",
        "2. Larger learning rates 0.05 for e.g. lead to unstable model in validation data and overall poor scores in training and test\n",
        "3. Learning rates of 0.005 give more stable results early in the epoch. Becomes overfit with more epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqOFB6fpmgot",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Descent Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8r5n6-vmgou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dense(num_classes, activation='softmax'))  \n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCCzHt-Qmgox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "def run_model(model):\n",
        "    batch_size = 256    # keep in 2^x \n",
        "    epochs = 20\n",
        "    model.summary()\n",
        "#   sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    sgd = optimizers.Adam(lr=0.01, decay=1e-6)\n",
        "#    sgd = optimizers.rmsprop(lr=0.01, decay=1e-6)\n",
        "\n",
        "\n",
        "  \n",
        "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
        "    loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "  \n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(f'Test loss: {loss:.3}')\n",
        "    print(f'Test accuracy: {accuracy:.3}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFNosG34mgo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "run_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHy7nUm6mgo7",
        "colab_type": "text"
      },
      "source": [
        "# Dropout based regularization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnrRKywCmgo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.constraints import max_norm\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, activation='relu', input_shape=(784,), kernel_constraint = max_norm(2)))\n",
        "    model.add(Dropout(0.3) )  # 30% drop out for the first hidden layer   ----- > drop out\n",
        "    model.add(Dense(num_classes, activation='softmax'))  \n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FXYxTknmgo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "def run_model(model):\n",
        "    batch_size = 256    \n",
        "    epochs = 20\n",
        "    model.summary()\n",
        "    opt = optimizers.Adam(lr=0.05)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
        "    loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "  \n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(f'Test loss: {loss:.3}')\n",
        "    print(f'Test accuracy: {accuracy:.3}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "K7-WbqYgmgpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "run_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-lPbGT1mgpH",
        "colab_type": "text"
      },
      "source": [
        "## Observations about Dropout \n",
        "\n",
        "1. Dropout layer on a simple model with one hidden layer seems to have an adverese impact.\n",
        "2. Dropout layer is leading to unstable behavior in the model bothin training and testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8FO4PDTmgpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model with two layers of 128 neurons each to see the impact of drop out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnlV6Oy-mgpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.constraints import max_norm\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2) )  # drop out for the second hidden layer   ----- > drop out\n",
        "    model.add(Dense(128, activation='relu',  kernel_constraint = max_norm(2) ))\n",
        "    model.add(Dropout(0.2) )  # drop out for the second hidden layer   ----- > drop out\n",
        "    model.add(Dense(num_classes, activation='softmax'))  \n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oV5qc5UmgpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(model):\n",
        "    batch_size = 256    \n",
        "    epochs = 20\n",
        "    model.summary()\n",
        "    opt = optimizers.Adam(lr=0.005)\n",
        "  \n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
        "    loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "  \n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print()\n",
        "    print(f'Test loss: {loss:.3}')\n",
        "    print(f'Test accuracy: {accuracy:.3}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlFWiM8zmgpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "run_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzZ1r-ygmgpb",
        "colab_type": "text"
      },
      "source": [
        "## Observation on Dropout layer with multiple layers\n",
        "\n",
        "1. Dropout layer in itself did not help. Neither did the Kernel_constraint. These parameters are probably more useful in deep\n",
        "neural network\n",
        "2. Learning rate value of .005 got some decent results. Here too, in the initial epochs the model is unstable and starts \n",
        "overfitting with increasing epochs\n",
        "3. \n",
        "\n",
        "4. To prevent the model from becoming overfit, split the 256 neurons into two layers of 128 with drop layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0jlO82Omgpd",
        "colab_type": "text"
      },
      "source": [
        "# Weight Initialization \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_avQtWumgpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.initializers import he_normal\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(88, activation='relu', input_shape=(784,), kernel_initializer = he_normal(seed=None)))\n",
        "    model.add(Dropout(0.1))  # drop out for the first hidden layer   ----- > drop out\n",
        "    model.add(Dense(72, activation='relu', kernel_initializer = he_normal(seed=None)))\n",
        "    model.add(Dropout(0.2) )  # drop out for the second hidden layer   ----- > drop out\n",
        "    model.add(Dense(num_classes, activation='softmax'))  \n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNn36ZUjmgpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(model):\n",
        "    batch_size = 30000    \n",
        "    epochs = 20\n",
        "    model.summary()\n",
        "    opt = optimizers.Adam(lr=0.005)\n",
        "  \n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
        "    loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "  \n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print()\n",
        "    print(f'Test loss: {loss:.3}')\n",
        "    print(f'Test accuracy: {accuracy:.3}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOo9uySKmgpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "run_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwLz5m9ymgps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ta = pd.DataFrame(history.history['accuracy'])\n",
        "va = pd.DataFrame(history.history['val_accuracy'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeBawUdnmgpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Observations of including kernel initialier of He_norm and other parameters\n",
        "1. Frustrating! the model was looking very unstable with all the combinations of parameter values\n",
        "2. raised the batch size to 30,000 and got rid of the instability\n",
        "3. Avg accuracy of 98% in validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpdIw3Zimgp3",
        "colab_type": "text"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttan9H3ymgp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.constraints import maxnorm\n",
        "from keras import backend as keras_backend\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "random_seed = 64\n",
        "np.random.seed(random_seed)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc7daxr_mgp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "num_classes = 10\n",
        "x_train = x_train.reshape(60000, 784)    # 784 = 28 X 28 the size of each image. There are 60000 images for training\n",
        "x_test = x_test.reshape(10000, 784)      # Images are flattended out into a vector of 784 elements\n",
        "x_train = keras_backend.cast_to_floatx(x_train)      # Change the data type to float from integer (0 - 255)\n",
        "x_test = keras_backend.cast_to_floatx(x_test)\n",
        "x_train /= 255.0                           # Scale the data between 0 and 1\n",
        "x_test /= 255.0\n",
        "\n",
        "original_y_train = y_train\n",
        "original_y_test = y_test\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)   # Converting the target into categorical which is stored as numeric\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)     # Keras converst these into 1-hot coded vectors as these are lables\n",
        "\n",
        "\n",
        "print ('Train size:', x_train.shape[0])\n",
        "print ('Test size:', x_test.shape[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rD8qYPOmgqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(number_of_layers=2, neurons_per_layer = 32, dropout_percent = 0.2, optimizer='adam'):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons_per_layer, activation='relu', input_shape=(784,)))\n",
        "    \n",
        "    for i in range(number_of_layers-1):\n",
        "        model.add(Dense(neurons_per_layer, activation='relu', kernel_constraint = maxnorm(3)))\n",
        "        model.add(Dropout(dropout_percent))\n",
        "        \n",
        "    # Add the output layer with softmax\n",
        "    model.add(Dense(num_classes, kernel_initializer = 'normal', activation='softmax'))  \n",
        "        \n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "   \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-RC-2n0mgqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "kc_model = KerasClassifier(build_fn=create_model,number_of_layers=2, neurons_per_layer = 256, optimizer = 'adam', epochs=20, batch_size=30000, verbose=0) # Wrapper for scikitlearn API, provides \n",
        "                                                                                    # facility to get scores \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpt6WkAPmgqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold = StratifiedKFold(n_splits = 2, shuffle=True, random_state = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugmgivc2mgqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = cross_val_score(kc_model, x_train, original_y_train, cv=kfold, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFWDVHrmmgqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('results = {}\\nresults.mean = {}'.format(results, results.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTbo3yI2mgqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the grid search parameters\n",
        "\n",
        "param_grid = dict(number_of_layers = [2 , 3],\n",
        "                 neurons_per_layer = [32 , 128],\n",
        "                 optimizer = ['adam', 'sgd'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hon-b-KJmgqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gridsearcher = GridSearchCV(estimator=kc_model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = gridsearcher.fit(x_train, original_y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik38hDpcmgqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3teIkY91mgqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#learn_rate = [0.001, 0.002]\n",
        "#momentum = [0.0, 0.1, 0.3]\n",
        "#optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "#init_mode = ['uniform', 'lecun_uniform', 'normal', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "# activation = ['relu', 'tanh', 'sigmoid']\n",
        "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "#neurons = [10, 12, 13, 14, 15]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSbUEIH8mgqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}